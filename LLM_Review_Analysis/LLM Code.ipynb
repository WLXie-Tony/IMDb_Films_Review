{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af5ca6a-859c-4dfa-8dc7-0e2eb39ee9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any, Optional, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a6034-7dc6-4b4f-acab-168e6b9a06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"Put Your GPT API Key Code\"\n",
    "\n",
    "# Create client with longer timeout\n",
    "client = OpenAI(\n",
    "    timeout=httpx.Timeout(120.0)\n",
    ")\n",
    "\n",
    "def get_completion_with_retry(\n",
    "    prompt: str, \n",
    "    model: str = \"gpt-4o\",\n",
    "    temperature: float = 0.2,\n",
    "    max_retries: int = 5,\n",
    "    initial_retry_delay: float = 5,\n",
    "    max_tokens: Optional[int] = 1000,\n",
    "    presence_penalty: float = 0,\n",
    "    frequency_penalty: float = 0\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Send request to OpenAI API with error handling and retry logic\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    retries = 0\n",
    "    \n",
    "    while retries <= max_retries:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens,\n",
    "                presence_penalty=presence_penalty,\n",
    "                frequency_penalty=frequency_penalty\n",
    "            )\n",
    "            \n",
    "            return response.choices[0].message.content\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {retries + 1} failed, error: {type(e).__name__}: {str(e)}\")\n",
    "            \n",
    "            if retries >= max_retries:\n",
    "                print(f\"Maximum retry attempts reached. Returning empty result and continuing.\")\n",
    "                return \"{}\"\n",
    "            \n",
    "            wait_time = initial_retry_delay * (2 ** retries)\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            \n",
    "            time.sleep(wait_time)\n",
    "            retries += 1\n",
    "\n",
    "def analyze_movie_review(\n",
    "    review_text: str, \n",
    "    movie_title: str, \n",
    "    director: str,\n",
    "    writers: str,\n",
    "    release_year: int,\n",
    "    budget: float,\n",
    "    gross: float,\n",
    "    opening_weekend: float,\n",
    "    roi: float,\n",
    "    official_rating: float,\n",
    "    user_rating: Optional[float] = None,\n",
    "    language: str = \"\",\n",
    "    country: str = \"\",\n",
    "    filming_locations: str = \"\",\n",
    "    production_companies: str = \"\"\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze movie review using OpenAI API\n",
    "    \"\"\"\n",
    "    # Create prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are a professional film critic and sentiment analysis expert. Please analyze the following movie review and provide a detailed sentiment analysis.\n",
    "\n",
    "    MOVIE INFORMATION:\n",
    "    - Title: {movie_title}\n",
    "    - Director: {director}\n",
    "    - Writers: {writers}\n",
    "    - Release Year: {release_year}\n",
    "    - Budget: ${budget:,.0f}\n",
    "    - Opening Weekend (US/Canada): ${opening_weekend:,.0f}\n",
    "    - Worldwide Gross: ${gross:,.0f}\n",
    "    - ROI: {roi:.2f}\n",
    "    - IMDb Rating: {official_rating}/10\n",
    "    - User Rating: {user_rating if user_rating else \"Not provided\"}/10\n",
    "    - Language: {language}\n",
    "    - Country of Origin: {country}\n",
    "    - Filming Locations: {filming_locations}\n",
    "    - Production Companies: {production_companies}\n",
    "\n",
    "    REVIEW TEXT:\n",
    "    \"{review_text}\"\n",
    "\n",
    "    Analyze this review's sentiment and attitude. Return ONLY a JSON object with the following keys:\n",
    "    1. sentiment_score: Score from 1-10 (1=extremely negative, 10=extremely positive)\n",
    "    2. emotion_keywords: List of 5 keywords/phrases that best represent the emotional tone\n",
    "    3. primary_emotion: Main emotion expressed (e.g., admiration, disappointment, anger, surprise)\n",
    "    4. review_focus: What aspects the review focuses on (e.g., plot, acting, visuals, directing)\n",
    "    5. bias_analysis: Analysis of potential biases or subjective factors\n",
    "    6. summary: Brief summary (50 words or less)\n",
    "\n",
    "    Return ONLY the JSON result with no additional text or explanation.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Call API for analysis\n",
    "        response = get_completion_with_retry(prompt)\n",
    "        \n",
    "        # Parse JSON response\n",
    "        try:\n",
    "            result = json.loads(response)\n",
    "            return result\n",
    "        except json.JSONDecodeError:\n",
    "            # Try to extract JSON portion if full parsing fails\n",
    "            if '{' in response and '}' in response:\n",
    "                json_str = response[response.find('{'):response.rfind('}')+1]\n",
    "                try:\n",
    "                    return json.loads(json_str)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            # Return default result if parsing fails\n",
    "            print(f\"Could not parse response as JSON, using default values: {response[:100]}...\")\n",
    "            return {\n",
    "                \"sentiment_score\": 5,\n",
    "                \"emotion_keywords\": [\"parsing_failed\"],\n",
    "                \"primary_emotion\": \"unknown\",\n",
    "                \"review_focus\": \"unknown\",\n",
    "                \"bias_analysis\": \"analysis_failed\",\n",
    "                \"summary\": \"Failed to parse review content\"\n",
    "            }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing review: {str(e)}\")\n",
    "        # Return default result instead of failing\n",
    "        return {\n",
    "            \"sentiment_score\": 5,\n",
    "            \"emotion_keywords\": [\"analysis_failed\"],\n",
    "            \"primary_emotion\": \"unknown\",\n",
    "            \"review_focus\": \"unknown\",\n",
    "            \"bias_analysis\": \"analysis_failed\",\n",
    "            \"summary\": \"Error during analysis process\"\n",
    "        }\n",
    "\n",
    "def analyze_movie_reviews_batch(df, sample_size=None, start_idx=0, save_interval=5):\n",
    "    \"\"\"\n",
    "    Batch analyze movie reviews dataset\n",
    "    \n",
    "    Parameters:\n",
    "        df: DataFrame containing movie reviews\n",
    "        sample_size: Sample size to process (None means process all)\n",
    "        start_idx: Starting index for continuation\n",
    "        save_interval: How often to save results\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with analysis results\n",
    "    \"\"\"\n",
    "    # Select data to process\n",
    "    if sample_size is not None:\n",
    "        df_to_process = df.iloc[start_idx:start_idx + sample_size].copy()\n",
    "    else:\n",
    "        df_to_process = df.iloc[start_idx:].copy()\n",
    "    \n",
    "    # Create new columns for results\n",
    "    df_to_process['sentiment_score'] = None\n",
    "    df_to_process['emotion_keywords'] = None\n",
    "    df_to_process['primary_emotion'] = None\n",
    "    df_to_process['review_focus'] = None\n",
    "    df_to_process['bias_analysis'] = None\n",
    "    df_to_process['summary'] = None\n",
    "    \n",
    "    # Create save directory\n",
    "    save_dir = \"movie_analysis_results\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each review\n",
    "    for i, (idx, row) in enumerate(tqdm(df_to_process.iterrows(), total=len(df_to_process), desc=\"Analyzing reviews\")):\n",
    "        # Skip empty reviews\n",
    "        if pd.isna(row['Comments']):\n",
    "            print(f\"Skipping empty review at index {idx}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Analyze review\n",
    "            result = analyze_movie_review(\n",
    "                review_text=str(row['Comments'])[:3000],  # Limit review length\n",
    "                movie_title=str(row['Title']),\n",
    "                director=str(row['Director']),\n",
    "                writers=str(row['Writers']),\n",
    "                release_year=int(row['Release_Year']),\n",
    "                budget=float(row['Budget']),\n",
    "                opening_weekend=float(row['Opening_Weekend_US_Canada']),\n",
    "                gross=float(row['Gross_Worldwide']),\n",
    "                roi=float(row['ROI']),\n",
    "                official_rating=float(row['Rating_movie']),\n",
    "                user_rating=float(row['Review_Rating']) if not pd.isna(row['Review_Rating']) else None,\n",
    "                language=str(row['Language']),\n",
    "                country=str(row['Country_of_origin']),\n",
    "                filming_locations=str(row['Filming_Locations']),\n",
    "                production_companies=str(row['Production_Companies'])\n",
    "            )\n",
    "            \n",
    "            # Save results to DataFrame\n",
    "            df_to_process.at[idx, 'sentiment_score'] = result.get('sentiment_score')\n",
    "            df_to_process.at[idx, 'emotion_keywords'] = str(result.get('emotion_keywords', []))\n",
    "            df_to_process.at[idx, 'primary_emotion'] = result.get('primary_emotion')\n",
    "            df_to_process.at[idx, 'review_focus'] = result.get('review_focus')\n",
    "            df_to_process.at[idx, 'bias_analysis'] = result.get('bias_analysis')\n",
    "            df_to_process.at[idx, 'summary'] = result.get('summary')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing review at index {idx}: {str(e)}\")\n",
    "            # Record error but continue processing\n",
    "            df_to_process.at[idx, 'summary'] = f\"Processing error: {str(e)[:100]}\"\n",
    "        \n",
    "        # Save results periodically\n",
    "        if (i + 1) % save_interval == 0 or i == len(df_to_process) - 1:\n",
    "            save_path = os.path.join(save_dir, f\"movie_reviews_analysis_{start_idx}_{start_idx + i + 1}.xlsx\")\n",
    "            try:\n",
    "                df_to_process.iloc[:i+1].to_excel(save_path, index=False)\n",
    "                print(f\"Completed {i + 1}/{len(df_to_process)} reviews, results saved to {save_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving results to {save_path}: {str(e)}\")\n",
    "                # Try saving as CSV (more reliable)\n",
    "                csv_path = save_path.replace('.xlsx', '.csv')\n",
    "                try:\n",
    "                    df_to_process.iloc[:i+1].to_csv(csv_path, index=False)\n",
    "                    print(f\"Saved as CSV instead: {csv_path}\")\n",
    "                except:\n",
    "                    print(\"Failed to save CSV as well, continuing but may lose partial results\")\n",
    "    \n",
    "    # Save final results\n",
    "    final_path = os.path.join(save_dir, f\"movie_reviews_analysis_final_{start_idx}_{start_idx + len(df_to_process)}.xlsx\")\n",
    "    try:\n",
    "        df_to_process.to_excel(final_path, index=False)\n",
    "        print(f\"Analysis complete! Final results saved to {final_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving final results: {str(e)}\")\n",
    "        # Try saving as CSV\n",
    "        final_csv = final_path.replace('.xlsx', '.csv')\n",
    "        df_to_process.to_csv(final_csv, index=False)\n",
    "        print(f\"Saved final results as CSV: {final_csv}\")\n",
    "    \n",
    "    return df_to_process\n",
    "\n",
    "# 主函数\n",
    "def main():\n",
    "    try:\n",
    "        # 读取电影评论数据\n",
    "        print(\"正在读取电影评论数据...\")\n",
    "        df = pd.read_excel(r\"E:\\MTL\\Data\\Exmperience Test\\IMDb_All_Information_Review.xlsx\")\n",
    "        \n",
    "        print(f\"共读取 {len(df)} 条评论\")\n",
    "        \n",
    "        # 询问用户是否使用样本\n",
    "        use_sample = input(\"是否只处理部分样本数据？(y/n): \").lower() == 'y'\n",
    "        \n",
    "        if use_sample:\n",
    "            sample_size = int(input(\"请输入样本大小: \"))\n",
    "            start_idx = int(input(\"请输入起始索引（用于断点续传，默认0）: \") or \"0\")\n",
    "        else:\n",
    "            sample_size = None\n",
    "            start_idx = int(input(\"请输入起始索引（用于断点续传，默认0）: \") or \"0\")\n",
    "        \n",
    "        # 设置保存间隔\n",
    "        save_interval = int(input(\"请输入保存间隔（每处理多少条评论保存一次，默认5）: \") or \"5\")\n",
    "        \n",
    "        # 分析评论\n",
    "        print(\"开始分析电影评论...\")\n",
    "        results_df = analyze_movie_reviews_batch(df, sample_size, start_idx, save_interval)\n",
    "        \n",
    "        print(f\"全部分析完成！\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"程序执行过程中出现严重错误: {str(e)}\")\n",
    "        print(\"请检查错误信息并重新运行程序。\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
